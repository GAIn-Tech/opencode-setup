{
  "version": "0.1.0",
  "description": "Policy-based routing rules for OpenCode model selection",

  "models": {
    "openai/moonshotai/kimi-k2.5": {
      "provider": "openai",
      "tier": "flagship",
      "base_weight": 0.6,
      "cost_per_1k_tokens": 0.012,
      "max_context": 262144,
      "strengths": ["orchestration", "deep-reasoning", "long-context", "architecture"],
      "default_success_rate": 0.92
    },
    "openai/z-ai/glm4.7": {
      "provider": "openai",
      "tier": "flagship",
      "base_weight": 0.58,
      "cost_per_1k_tokens": 0.014,
      "max_context": 131072,
      "strengths": ["code-generation", "debugging", "refactoring", "tool-use"],
      "default_success_rate": 0.9
    },
    "openai/stepfun-ai/step-3.5-flash": {
      "provider": "openai",
      "tier": "speed",
      "base_weight": 0.54,
      "cost_per_1k_tokens": 0.006,
      "max_context": 262144,
      "strengths": ["fast-iteration", "simple-tasks", "formatting", "summarization"],
      "default_success_rate": 0.86
    },
    "openai/minimaxai/minimax-m2.1": {
      "provider": "openai",
      "tier": "balanced",
      "base_weight": 0.55,
      "cost_per_1k_tokens": 0.01,
      "max_context": 204800,
      "strengths": ["exploration", "alternative-perspective", "analysis", "planning"],
      "default_success_rate": 0.87
    },
    "openai/nvidia/nemotron-3-nano-30b-a3b": {
      "provider": "openai",
      "tier": "balanced",
      "base_weight": 0.53,
      "cost_per_1k_tokens": 0.004,
      "max_context": 1048576,
      "strengths": ["long-context", "reasoning", "cost-efficiency", "fallback"],
      "default_success_rate": 0.84
    },
    "openai/moonshotai/kimi-k2": {
      "provider": "openai",
      "tier": "balanced",
      "base_weight": 0.5,
      "cost_per_1k_tokens": 0.009,
      "max_context": 131072,
      "strengths": ["general-code", "orchestration", "translation", "summarization"],
      "default_success_rate": 0.85
    },
    "openai/meta/llama-3.1-70b-instruct": {
      "provider": "openai",
      "tier": "speed",
      "base_weight": 0.48,
      "cost_per_1k_tokens": 0.003,
      "max_context": 128000,
      "strengths": ["quick-answers", "simple-tasks", "extraction", "fallback"],
      "default_success_rate": 0.82
    }
  },

  "cost_tiers": {
    "mechanical":  { "max_budget": 0.02, "preferred_tier": "speed",     "description": "Formatting, linting, trivial fixes" },
    "trivial":     { "max_budget": 0.05, "preferred_tier": "speed",     "description": "Simple renames, small edits" },
    "low":         { "max_budget": 0.10, "preferred_tier": "balanced",  "description": "Standard code changes, tests" },
    "medium":      { "max_budget": 0.25, "preferred_tier": "balanced",  "description": "Feature implementation, refactoring" },
    "high":        { "max_budget": 0.50, "preferred_tier": "flagship",  "description": "Complex features, architecture" },
    "critical":    { "max_budget": 1.00, "preferred_tier": "flagship",  "description": "Critical bugs, security fixes" },
    "emergency":   { "max_budget": 2.00, "preferred_tier": "flagship",  "description": "Production incidents, urgent fixes" }
  },

  "complexity_routing": {
    "simple": {
      "description": "Mechanical tasks, formatting, linting",
      "cost_tier": "mechanical",
      "model_preference": ["openai/stepfun-ai/step-3.5-flash", "openai/meta/llama-3.1-70b-instruct", "openai/nvidia/nemotron-3-nano-30b-a3b"]
    },
    "moderate": {
      "description": "Standard code tasks, tests, small features",
      "cost_tier": "low",
      "model_preference": ["openai/z-ai/glm4.7", "openai/minimaxai/minimax-m2.1", "openai/moonshotai/kimi-k2"]
    },
    "high": {
      "description": "Complex features, multi-file refactors",
      "cost_tier": "high",
      "model_preference": ["openai/moonshotai/kimi-k2.5", "openai/z-ai/glm4.7", "openai/minimaxai/minimax-m2.1"]
    },
    "critical": {
      "description": "Architecture decisions, security, production issues",
      "cost_tier": "critical",
      "model_preference": ["openai/moonshotai/kimi-k2.5", "openai/z-ai/glm4.7", "openai/nvidia/nemotron-3-nano-30b-a3b"]
    }
  },

  "tuning": {
    "min_samples_for_tuning": 5,
    "decay_factor": 0.95,
    "success_rate_floor": 0.3,
    "success_rate_ceiling": 0.99,
    "latency_penalty_threshold_ms": 30000,
    "latency_penalty_factor": 0.1
  }
}
